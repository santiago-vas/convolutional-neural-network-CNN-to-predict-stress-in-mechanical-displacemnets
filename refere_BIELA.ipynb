{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "refere_BIELA.ipynb",
      "provenance": [],
      "mount_file_id": "1WHVn0hHeSly57TeOxvSc5o18_0tuVrM5",
      "authorship_tag": "ABX9TyNe2I9DX6FaTs5xEQIccQ2L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santiago-vas/convolutional-neural-network-CNN-to-predict-stress-in-mechanical-displacemnets/blob/main/refere_BIELA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYMnJQ9sf7LR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03d60988-5bdf-4d07-e1b6-ab4d4d4fb2be"
      },
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from numpy import asarray\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "import keras.backend as K\n",
        "from keras import metrics\n",
        "from numpy.random import RandomState\n",
        "import scipy.io\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "rng=RandomState(0)\n",
        "\n",
        "w1 = scipy.io.loadmat('/content/drive/My Drive/Colab Notebooks/pca BIELA E/parte 1/B_peso1.mat')\n",
        "w2 = scipy.io.loadmat('/content/drive/My Drive/Colab Notebooks/pca BIELA E/parte 1/B_100_peso2.mat')\n",
        "out = scipy.io.loadmat('/content/drive/My Drive/Colab Notebooks/pca BIELA E/parte 1/B_100_salidaFinal.mat')\n",
        "L = scipy.io.loadmat('/content/drive/My Drive/Colab Notebooks/pca BIELA E/parte 1/B_100_valoresLL2.mat')\n",
        "\n",
        "L=L['uLL2']\n",
        "ww1=w1['aW1']\n",
        "ww2=w2['bW2']\n",
        "ref = out['YF']\n",
        "\n",
        "inEst = pd.read_excel('/content/drive/My Drive/Colab Notebooks/arreglar datos de la BIELA ESTANDAR/_in_var_PREF.xlsx')\n",
        "inr=inEst.to_numpy()\n",
        "print(inr.shape,ref.shape,ww1.shape,ww2.shape,L.shape)\n",
        "# ,ref.shape,ww1.shape,ww2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(90, 3) (1, 1, 150, 90) (8, 19, 2, 280) (4, 4, 280, 150) (4480, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WT3dVBr5Jdu"
      },
      "source": [
        "def CreateModel_NonlinearMapping(Xshape, Yshape):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(Yshape*2, input_shape=(Xshape,), kernel_initializer='normal', activation='softplus'))\n",
        "  model.add(Dense(Yshape*2, kernel_initializer='normal', activation='softplus'))\n",
        "  model.add(Dense(Yshape, kernel_initializer='normal', activation='linear'))\n",
        "  # model.compile(loss='mean_squared_error', optimizer='adamax')\n",
        "  model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adamax(learning_rate=0.0005))\n",
        "  return model\n",
        "\n",
        "def CreateModel_StressDecoding(W1_in, W2_in,entrada):\n",
        "  model = Sequential()\n",
        "  pca_valor2=280\n",
        "  model.add(Conv2DTranspose(filters=pca_valor2, kernel_size=[4,4], strides=(1,1), input_shape=(1,1,entrada),data_format='channels_last'))\n",
        "  model.add(Conv2DTranspose(filters=2, kernel_size=[8,19], strides=(8,19)))\n",
        "  model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001))\n",
        "  W0=model.layers[0].get_weights()\n",
        "  W1=model.layers[1].get_weights()\n",
        "  W0[0]=W2_in\n",
        "  W1[0]=W1_in\n",
        "  model.layers[0].set_weights(W0)\n",
        "  model.layers[1].set_weights(W1)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocjRvxwkiYT_"
      },
      "source": [
        "muestra=90\n",
        "nodos=1860\n",
        "entrada=3\n",
        "salida=150\n",
        "veces=50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDWJsGwN9dKe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0e2edc75-3c71-4209-9d00-475a7e667c85"
      },
      "source": [
        "muestra=90\n",
        "nodos=1860\n",
        "entrada=3\n",
        "salida=150\n",
        "veces=50\n",
        "inr2=inr\n",
        "ref2=ref.reshape(-1,muestra)\n",
        "ref2=ref2.transpose()\n",
        "# print(inr2[0,:])\n",
        "# print(ref2[0,:])\n",
        "print(inr2.shape)\n",
        "print(ref2.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90, 3)\n",
            "(90, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBcvuDn8kdFw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "66549468-1256-4cd6-b6fd-9959d97e23f5"
      },
      "source": [
        "muestra=90\n",
        "nodos=1860\n",
        "entrada=3\n",
        "salida=150\n",
        "veces=50\n",
        "inr2=inr\n",
        "ref2=ref.reshape(-1,muestra)\n",
        "ref2=ref2.transpose()\n",
        "# print(inr2[0,:])\n",
        "# print(ref2[0,:])\n",
        "print(inr2.shape)\n",
        "print(ref2.shape)\n",
        "#*********************************\n",
        "qlpca=QuantileTransformer()\n",
        "qpca=qlpca.fit_transform(ref2)\n",
        "#**********************************"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py:2357: UserWarning: n_quantiles (1000) is greater than the total number of samples (90). n_quantiles is set to n_samples.\n",
            "  % (self.n_quantiles, n_samples))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxjI5kBv6sh1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "913d3d50-fb9f-4703-852a-ba3f391c8d72"
      },
      "source": [
        "muestra=90\n",
        "nodos=1860\n",
        "entrada=3\n",
        "salida=150\n",
        "veces=50\n",
        "inr2=inr\n",
        "ref2=ref.reshape(-1,muestra)\n",
        "ref2=ref2.transpose()\n",
        "# print(inr2[0,:])\n",
        "# print(ref2[0,:])\n",
        "print(inr2.shape)\n",
        "print(ref2.shape)\n",
        "#*********************************\n",
        "qlpca=QuantileTransformer()\n",
        "qpca=qlpca.fit_transform(ref2)\n",
        "#**********************************\n",
        "\n",
        "\n",
        "model=CreateModel_NonlinearMapping(entrada,salida)\n",
        "\n",
        "# model = keras.models.load_model('/content/drive/My Drive/Colab Notebooks/pca BIELA E/parte 1/B_red1_referencia.h5')\n",
        "veces\n",
        "loss=np.zeros(veces)\n",
        "\n",
        "for k in range(veces):\n",
        "  id=np.arange(0,muestra,1)\n",
        "  rng.shuffle(id)\n",
        "  id_train=id[0:int(muestra*0.9)]\n",
        "  id_test=id[int(muestra*0.9):]\n",
        "\n",
        "  rp1=inr2[id_train,:]\n",
        "  rp2=inr2[id_test,:]\n",
        "\n",
        "  # rx1=ref2[id_train,:]\n",
        "  # rx2=ref2[id_test,:]\n",
        "  rx1=qpca[id_train,:]\n",
        "  rx2=qpca[id_test,:]\n",
        "\n",
        "  model.fit(rp1,rx1, epochs=5000,batch_size=10, verbose=0)\n",
        "  loss[k]=model.evaluate(rp2,rx2,verbose=0)\n",
        "  print(k,loss[k])\n",
        "\n",
        "ploss= pd.DataFrame(loss)\n",
        "ploss.to_excel('/content/drive/My Drive/Colab Notebooks/pca BIELA E/parte 1/B_errorMSE_red1_v2.xlsx', index=False)\n",
        "model.save('/content/drive/My Drive/Colab Notebooks/pca BIELA E/parte 1/B_red1_referencia_v2.h5')\n",
        "joblib.dump(qlpca,'/content/drive/My Drive/Colab Notebooks/pca BIELA E/parte 1/B_qlpca_referencia.pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.004199352581053972\n",
            "1 0.003893052926287055\n",
            "2 0.006439791060984135\n",
            "3 0.0020506626460701227\n",
            "4 0.001875799149274826\n",
            "5 0.01047238428145647\n",
            "6 0.002410539425909519\n",
            "7 0.005316359922289848\n",
            "8 0.009172886610031128\n",
            "9 0.003017590381205082\n",
            "10 0.0018543095793575048\n",
            "11 0.0018878084374591708\n",
            "12 0.0023602203000336885\n",
            "13 0.0036406053695827723\n",
            "14 0.0034066748339682817\n",
            "15 0.002367190085351467\n",
            "16 0.002873549470677972\n",
            "17 0.008777011185884476\n",
            "18 0.014415547251701355\n",
            "19 0.004390094429254532\n",
            "20 0.018647832795977592\n",
            "21 0.006238247267901897\n",
            "22 0.0024469299241900444\n",
            "23 0.002285931259393692\n",
            "24 0.0006155946175567806\n",
            "25 0.0012006741017103195\n",
            "26 0.004284609109163284\n",
            "27 0.0018583906348794699\n",
            "28 0.004100462421774864\n",
            "29 0.0044237105175852776\n",
            "30 0.006001447327435017\n",
            "31 0.003867226419970393\n",
            "32 0.0018771191826090217\n",
            "33 0.001537557109259069\n",
            "34 0.019457314163446426\n",
            "35 0.011977961286902428\n",
            "36 0.001369425212033093\n",
            "37 0.0007795029086992145\n",
            "38 0.0009632774745114148\n",
            "39 0.004981744568794966\n",
            "40 0.008882922120392323\n",
            "41 0.0012147361412644386\n",
            "42 0.00438374187797308\n",
            "43 0.0013558384962379932\n",
            "44 0.0010036258026957512\n",
            "45 0.004003387875854969\n",
            "46 0.00036737899063155055\n",
            "47 0.0009331332985311747\n",
            "48 0.0012160175247117877\n",
            "49 0.006311037112027407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/Colab Notebooks/pca BIELA E/parte 1/B_qlpca_referencia.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM1uJdlLTZ0v"
      },
      "source": [
        "a=0\n",
        "print(inr[a:a+1,:])\n",
        "print(ref2[a:a+1,:])\n",
        "####### model = keras.models.load_model('/content/drive/My Drive/Colab Notebooks/pca RIEL2D/parte1/20 pca/red1_dense_PCA20.h5')\n",
        "\n",
        "Yp=model.predict(inr[a:a+1,:])\n",
        "Yp=qlpca.inverse_transform(Yp)\n",
        "for n in range(0, salida):\n",
        "  Yp[:,n]=Yp[:,n]*L[n]\n",
        "Ypp=Yp.reshape(1,1,1,salida)\n",
        "print(Ypp.shape)\n",
        "\n",
        "Yp=model.predict(input)\n",
        "Yp=qlpca.inverse_transform(Yp)\n",
        "entrada_Encoder=salida\n",
        "Aconv=CreateModel_StressDecoding(ww1,ww2,entrada_Encoder)\n",
        "datos_equivalentes=decoder(ww1,ww2,entrada_Encoder)\n",
        "\n",
        "Aconv.save('/content/drive/My Drive/Colab Notebooks/pca BIELA E/parte 1/B_referencia_CONVT.h5')\n",
        "# puntos=Aconv.predict(Ypp)\n",
        "# punx=puntos[:,:,:,0].reshape(1860,order='F')\n",
        "# puny=puntos[:,:,:,1].reshape(1860,order='F')\n",
        "# # print(punf.shape)\n",
        "# plt.plot(punx,puny,'*')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}